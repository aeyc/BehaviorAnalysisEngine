# -*- coding: utf-8 -*-
"""anomaly_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s1aw5yRrMBR4CLkqCgAjnoiSpESKfiAj

# Mounting drive for file access
"""
#%%
#LIBRARIES
#Custom Library Connection
import sys
import os

#Data Processing
import pandas as pd
import numpy as np
import math
import datetime
from datetime import date, timedelta

#Execution Time
import time

#Memory Profiler
from memory_profiler import profile

#Plots
import matplotlib.pyplot as plt
import matplotlib.dates
from matplotlib.pyplot import figure
import plotly.graph_objects as go
import plotly.figure_factory as ff
import plotly.express as px

#Fourier Transform
from scipy.fft import fft
from scipy.signal import find_peaks


#Tensorflow
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler


np.random.seed(1)
tf.random.set_seed(1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed

#Anomaly Detection
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest

#MongoDb
from pymongo import MongoClient, errors

"""## Importing Custom Libraries"""

from models import*


from helperfunctions import*

"""## Read from spec.ini file """
import configparser
config = configparser.ConfigParser()
config.read('specs.ini') #Read paths, connection parameters from file
#%%CONSTANTS
ROW_LIMIT = 500000 #Maximum number of rows that will be read from database
#%% DB Connection
global_st = time.time()
st = time.time()
client = MongoClient(config["MONGODB"]["connection_string"], 
                        maxPoolSize=None,
                        unicode_decode_error_handler=config["MONGODB"]["error_handler"])
    
try:
    db = client.obc
    collections = db.list_collection_names()
    if len(collections)>0:
        print("Collections gathered with Mongo")
except errors.ServerSelectionTimeoutError:
    print("Have you started the mongo start up process?")
    #return
et = time.time()
elapsed_time = et - st
print('Execution time of data retrieving:', elapsed_time/60 , 'minutes\n')
#%%Anomaly detection algorithms
@profile #Memory Usage profiler for given method
def enter_point(df, type_of_data):
    
    st = time.time()
    
    df = anomaly_detection(df)
    #remove quotes to see plots
    """
    a = df.loc[df['anomaly'] == 1] #anomaly
    _ = plt.figure(figsize=(18,6))
    _ = plt.plot(df['Memoria Usata'], color='blue', label='Normal')
    _ = plt.plot(a['Memoria Usata'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')
    _ = plt.xlabel('Date and Time')
    _ = plt.ylabel('Memory Usage')
    _ = plt.title('Anomalies detected with 3 algorithms')
    _ = plt.legend(loc='best')
    plt.show();
    """
    et = time.time()
    elapsed_time = et - st
    print('Execution time of whole process with {}: {} minutes\n'.format(type_of_data,str(elapsed_time/60) ))
    return df
#%%
df = pd.DataFrame(db.data.find())

"""# Formatting Dataframe"""

#Formatting DF
#Convert dataframe "Timestamp" column from string to datetime type of object, therefore we can simplify problem as a timeseries prediction, 
#also timestamp is a unique value in our table that we can analyze data based on it

df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df = df.sort_values(by='Timestamp') #Can be changed to Session ID

df = df.reset_index(drop=True)
#%%
"""## Resample Hourly"""
df_h = df.set_index('Timestamp').resample('60min').mean()
df_h = df_h.reset_index()
df_h = df_h[df_h['Memoria Usata'].notna()]

#%%
"""## Feed algorithms"""
#Take results for resampled data
df_h = enter_point(df_h, "hourly resampled data")

#Take results for original data
df_test = enter_point(df, "original data")
#db.data.update_many({"anomaly_flag": {"$exists": False}}, {"$set": {"anomaly_flag": df_test.anomaly}})
#%%
#"""

df_current = pd.DataFrame(db.data.find())
while True:
    current = date.now() + timedelta(minutes = 10) #check continuously if the date is changed

    if pd.DataFrame(db.data.find({"Timestamp":{"$gt": current}})).iloc[-1].Timestamp not in df_current.Timestamp: #if there is new value in tha database
        df = pd.DataFrame(db.data.find({"Timestamp":{"$gt": current}}).limit(ROW_LIMIT))
        
        df['Timestamp'] = pd.to_datetime(df['Timestamp'])
        df = df.sort_values(by='Timestamp') 
        
        df = df.reset_index(drop=True)
        
        df_new = enter_point(df)
        
        df_current = df_current.append(df_new[df_new['Timestamp'] > max(df_current.Timestamp)])        
#%%
global_et = time.time()
elapsed_time = global_et - global_st
print('Execution time of whole process:', elapsed_time/60 , 'minutes\n')

