# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1derReHVn0P30RFlGd1TJ_IYd0RzidwCN
"""


"""# Dependencies

# Libraries
"""

#%%
#LIBRARIES
#Custom Library Connection
import sys
import os

#Data Processing
import pandas as pd
import numpy as np

import datetime


#Plots
import matplotlib.pyplot as plt
import matplotlib.dates
from matplotlib.pyplot import figure
import plotly.graph_objects as go
import plotly.figure_factory as ff
import plotly.express as px



import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
#from keras.preprocessing.sequence import TimeseriesGenerator


np.random.seed(1)
tf.random.set_seed(1)


#Anomaly Detection
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
#%%
"""# Train Test Split"""

def split_percentage(df, train_percentage):
  return df[:int(len(df_lstm)*train_percentage)], df[int(len(df_lstm)*(train_percentage)):]

def split_value(df, value):
    return df[:-value], df[-value:]

"""# Standatization of Features"""

def standartize(train, test):
  scaler = StandardScaler()
  scaler = scaler.fit(train)
  return scaler, scaler.transform(train), scaler.transform(test) #scaled train, scaled test

"""# Time Series Generation"""

def generateTS(scaled_train, n_input, n_features):
  return TimeseriesGenerator(scaled_train,scaled_train,length = n_input, batch_size = 10) #generator

# Write a function that calculates distance between each point and the centroid of the closest cluster
def getDistanceByPoint(data, model):
    """ Function that calculates the distance between a point and centroid of a cluster, 
            returns the distances in pandas series"""
    distance = []
    for i in range(0,len(data)): 
        Xa = np.array(data.loc[i])
        Xb = model.cluster_centers_[model.labels_[i]-1]
        distance.append(np.linalg.norm(Xa-Xb))
    return pd.Series(distance, index=data.index)
#%% Anomaly Detection Algorithms
def iqr(df, columns):
    iqr_anomalies = []
    for i in columns:
        # Calculate IQR for the 1st principal component (pc1)
        q1_pc1, q3_pc1 = df[i].quantile([0.25, 0.75])
        iqr_pc1 = q3_pc1 - q1_pc1
        # Calculate upper bounds for outlier for pc1
        upper_pc1 = q3_pc1 + (1.5*iqr_pc1)
    
        iqr_anomalies.append(((df['Memoria Usata']>upper_pc1)).astype('int'))
    
    return iqr_anomalies
        
def k_means(df, columns):
    kmeans_anomalies = []
    for i in columns: 
        kmeans = KMeans(n_clusters=2, random_state=42)
        kmeans.fit(np.array(df[i]).reshape(-1, 1))
        # Assume that 13% of the entire data set are anomalies 
        outliers_fraction = 0.13
        # get the distance between each point and its nearest centroid. The biggest distances are considered as anomaly
        distance = getDistanceByPoint(df[i], kmeans)
        # number of observations that equate to the 13% of the entire data set
        number_of_outliers = int(outliers_fraction*len(distance))
        # Take the minimum of the largest 13% of the distances as the threshold
        threshold = distance.nlargest(number_of_outliers).min()
    
        # anomaly1 contain the anomaly result of the above method Cluster (0:normal, 1:anomaly) 
        local = (distance >= threshold).astype(int) 
        mean_val_h = np.mean(df[i])
        for j in range(len(df)):
          if df.iloc[j][i] <= mean_val_h:
            local[j] = 0
        kmeans_anomalies.append(local)
        
    return kmeans_anomalies

def isolation_forest(df, columns):
    if_anomalies = []
    for i in columns:
        outliers_fraction = 0.13
        model = IsolationForest(contamination=outliers_fraction)
        model.fit(np.array(df[i]).reshape(-1, 1))
    
        local = pd.Series(model.predict(np.array(df[i]).reshape(-1, 1)))
        mean_val_h = np.mean(df[i])
        for j in range(len(df)):
          if df.iloc[j][i] <= mean_val_h:
            local[j] = 1
        if_anomalies.append(local)
        return if_anomalies
    
def anomaly_detection(df):
    #%%
    """# Anomaly Detection with Interquartile Range
    
    ## Without Filling Values
    """
    df_tmp = df
    #call iqr
    df_tmp["anomaly_i"] = iqr(df_tmp,["Memoria Usata"])[0]
    
    # plot anomalies with iqr without filling values
    a = df_tmp[df_tmp['anomaly_i'] == 1] #anomaly
    _ = plt.figure(figsize=(18,6))
    _ = plt.plot(df_tmp['Memoria Usata'], color='blue', label='Normal')
    _ = plt.plot(a['Memoria Usata'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')
    _ = plt.xlabel('Date and Time')
    _ = plt.ylabel('Memory Usage')
    _ = plt.title('Anomalies with IQR')
    _ = plt.legend(loc='best')
    plt.show();
    #%%
    """# Anomaly Detection with K Means Algorithm
    
    ## Without Filling Values
    """
    #call kmeans
    df_tmp = df_tmp.reset_index()
    df_tmp["anomaly_k"] = k_means(df_tmp,["Memoria Usata"])[0]
    
    a = df_tmp[df_tmp['anomaly_k'] == 1] #anomaly
    _ = plt.figure(figsize=(18,6))
    _ = plt.plot(df_tmp['Memoria Usata'], color='blue', label='Normal')
    _ = plt.plot(a['Memoria Usata'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')
    _ = plt.xlabel('Date and Time')
    _ = plt.ylabel('Memory Usage')
    _ = plt.title('Anomalies with K-Means Clustering Algorithm')
    _ = plt.legend(loc='best')
    plt.show();
    #%%
    # """# Anomaly Detection with Isolation Forest
    
    # ## Without Filling Values
    # """
    
    df_tmp['anomaly_f'] = isolation_forest(df_tmp,["Memoria Usata"])[0]
    
    df_tmp.anomaly_f[df_tmp['anomaly_f'] == 1] = 0
    df_tmp.anomaly_f[df_tmp['anomaly_f'] == -1] = 1
    
    # visualization
    df_tmp['anomaly_f'] = pd.Series(df_tmp['anomaly_f'].values, index=df_tmp.index)
    a = df_tmp.loc[df_tmp['anomaly_f'] == 1] #anomaly
    _ = plt.figure(figsize=(18,6))
    _ = plt.plot(df_tmp['Memoria Usata'], color='blue', label='Normal')
    _ = plt.plot(a['Memoria Usata'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')
    _ = plt.xlabel('Date and Time')
    _ = plt.ylabel('Memory Usage')
    _ = plt.title('Anomalies with Isolation Forest')
    _ = plt.legend(loc='best')
    plt.show();

    df_tmp["anomaly"] = [1 if (df_tmp["anomaly_i"].iloc[k]==1) & (df_tmp["anomaly_k"].iloc[k]==1) & (df_tmp["anomaly_f"].iloc[k]==1) else 0 for k in range(len(df_tmp))]
    return df_tmp